{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daito\\miniconda3\\envs\\NLP\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Daito\\miniconda3\\envs\\NLP\\Lib\\site-packages\\catalogue\\__init__.py:123: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models \n",
    "import bertopic\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel,LdaModel,LsiModel\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_format(texts):\n",
    "    return [str(t) for t in texts]\n",
    "\n",
    "def compute_word_occurences(texts):\n",
    "    words = itertools.chain.from_iterable(texts)\n",
    "    word_count = pd.Series(words).value_counts()\n",
    "    word_count = pd.DataFrame({\"Word\": word_count.index, \"Count\": word_count.values})\n",
    "    return word_count\n",
    "\n",
    "def get_l_texts(text_file): #text_file is a .txt file from preprocessing to avoid doing it again\n",
    "    l_texts=[]\n",
    "    with open(text_file, \"r\") as f:\n",
    "        line = f.readlines()\n",
    "        list_line = [l.strip() for l in line]\n",
    "        for l in list_line:\n",
    "            l_texts.append(ast.literal_eval(l))\n",
    "    return l_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['mass_shooting', 'texas', 'week', 'tv'], ['smith', 'join', 'diplo', 'nicky', 'jam', 'world_cup', 'official', 'song'], ['hugh', 'grant', 'marries', 'time', 'age'], ['jim_carrey', 'blasts', 'castrato', 'adam', 'schiff', 'democrats', 'artwork'], ['julianna', 'margulie', 'donald', 'poop', 'bag', 'pick', 'dog'], ['morgan_freeman', 'devastate', 'sexual_harassment', 'claim', 'undermine', 'legacy'], ['donald', 'lovin', 'mcdonald', 'jingle', 'tonight', 'bit'], ['watch', 'amazon', 'prime', 'week'], ['mike', 'myers', 'reveal', 'fourth', 'austin', 'power', 'film'], ['watch', 'hulu', 'week']] \n",
      " ['There Were 2 Mass Shootings In Texas Last Week, But Only 1 On TV', \"Will Smith Joins Diplo And Nicky Jam For The 2018 World Cup's Official Song\", 'Hugh Grant Marries For The First Time At Age 57', \"Jim Carrey Blasts 'Castrato' Adam Schiff And Democrats In New Artwork\", 'Julianna Margulies Uses Donald Trump Poop Bags To Pick Up After Her Dog', \"Morgan Freeman 'Devastated' That Sexual Harassment Claims Could Undermine Legacy\", \"Donald Trump Is Lovin' New McDonald's Jingle In 'Tonight Show' Bit\", 'What To Watch On Amazon Prime That’s New This Week', \"Mike Myers Reveals He'd 'Like To' Do A Fourth Austin Powers Film\", 'What To Watch On Hulu That’s New This Week'] \n",
      " 0    There Were 2 Mass Shootings In Texas Last Week...\n",
      "1    Will Smith Joins Diplo And Nicky Jam For The 2...\n",
      "2      Hugh Grant Marries For The First Time At Age 57\n",
      "3    Jim Carrey Blasts 'Castrato' Adam Schiff And D...\n",
      "4    Julianna Margulies Uses Donald Trump Poop Bags...\n",
      "5    Morgan Freeman 'Devastated' That Sexual Harass...\n",
      "6    Donald Trump Is Lovin' New McDonald's Jingle I...\n",
      "7    What To Watch On Amazon Prime That’s New This ...\n",
      "8    Mike Myers Reveals He'd 'Like To' Do A Fourth ...\n",
      "9           What To Watch On Hulu That’s New This Week\n",
      "Name: headline, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_json(\"News_Category_Dataset_v2.json\", lines=True, dtype={\"headline\": str})\n",
    "texts = force_format(dataset[\"headline\"])\n",
    "l_texts = get_l_texts(\"l_texts.txt\")\n",
    "print(l_texts[:10],\"\\n\",texts[:10],\"\\n\",dataset[\"headline\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 47649\n",
      "Number of documents: 200853\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary\n",
    "dictionary = corpora.Dictionary(l_texts)\n",
    "# Create a corpus\n",
    "corpus = [dictionary.doc2bow(text) for text in l_texts]\n",
    "\n",
    "print(\"Number of unique tokens: {}\".format(len(dictionary)))\n",
    "print(\"Number of documents: {}\".format(len(corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour les modèles disponibles dans la librairie gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics:  50  Coherence Score:  -0.282094881502408 0.5094184357556886\n",
      "Number of topics:  51  Coherence Score:  -0.2887068055109819 0.5170890273807071\n",
      "Number of topics:  52  Coherence Score:  -0.28654223883856744 0.5146926482367074\n",
      "Number of topics:  53  Coherence Score:  -0.2921405308571968 0.5217060201315133\n",
      "Number of topics:  54  Coherence Score:  -0.2915939252852845 0.5240190432138078\n",
      "Number of topics:  55  Coherence Score:  -0.2963163306976359 0.5276565855854817\n",
      "Number of topics:  56  Coherence Score:  -0.29463126864080774 0.5252333748127519\n",
      "Number of topics:  57  Coherence Score:  -0.2967325421189156 0.5275971462989143\n",
      "Number of topics:  58  Coherence Score:  -0.296684626854237 0.5267835173715181\n",
      "Number of topics:  59  Coherence Score:  -0.3010507549171909 0.5323793578015006\n",
      "Number of topics:  60  Coherence Score:  -0.30262437122217595 0.536823468826923\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m lda_model \u001b[38;5;241m=\u001b[39m LdaModel(corpus, num_topics\u001b[38;5;241m=\u001b[39mn, id2word\u001b[38;5;241m=\u001b[39mdictionary)\n\u001b[0;32m      5\u001b[0m coherence_model_cv\u001b[38;5;241m=\u001b[39m CoherenceModel(model\u001b[38;5;241m=\u001b[39mlda_model, texts\u001b[38;5;241m=\u001b[39ml_texts, dictionary\u001b[38;5;241m=\u001b[39mdictionary, coherence\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_v\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m coherence_score_cv \u001b[38;5;241m=\u001b[39m \u001b[43mcoherence_model_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coherence\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m coherence_model_npmi\u001b[38;5;241m=\u001b[39m CoherenceModel(model\u001b[38;5;241m=\u001b[39mlda_model, texts\u001b[38;5;241m=\u001b[39ml_texts, dictionary\u001b[38;5;241m=\u001b[39mdictionary, coherence\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_npmi\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m coherence_score_npmi \u001b[38;5;241m=\u001b[39m coherence_model_npmi\u001b[38;5;241m.\u001b[39mget_coherence()\n",
      "File \u001b[1;32mc:\\Users\\Daito\\miniconda3\\envs\\NLP\\Lib\\site-packages\\gensim\\models\\coherencemodel.py:614\u001b[0m, in \u001b[0;36mCoherenceModel.get_coherence\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_coherence\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    606\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get coherence value based on pipeline parameters.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \n\u001b[0;32m    608\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    612\u001b[0m \n\u001b[0;32m    613\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 614\u001b[0m     confirmed_measures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_coherence_per_topic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_measures(confirmed_measures)\n",
      "File \u001b[1;32mc:\\Users\\Daito\\miniconda3\\envs\\NLP\\Lib\\site-packages\\gensim\\models\\coherencemodel.py:586\u001b[0m, in \u001b[0;36mCoherenceModel.get_coherence_per_topic\u001b[1;34m(self, segmented_topics, with_std, with_support)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    584\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalize\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoherence \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_npmi\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeasure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmented_topics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accumulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daito\\miniconda3\\envs\\NLP\\Lib\\site-packages\\gensim\\topic_coherence\\indirect_confirmation_measure.py:177\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(segmented_topics, accumulator, topics, measure, gamma, with_std, with_support)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (w_prime, w_star) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(topic_segments):\n\u001b[0;32m    176\u001b[0m     w_prime_cv \u001b[38;5;241m=\u001b[39m context_vectors[w_prime, topic_words]\n\u001b[1;32m--> 177\u001b[0m     w_star_cv \u001b[38;5;241m=\u001b[39m \u001b[43mcontext_vectors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mw_star\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic_words\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    178\u001b[0m     segment_sims[i] \u001b[38;5;241m=\u001b[39m _cossim(w_prime_cv, w_star_cv)\n\u001b[0;32m    180\u001b[0m topic_coherences\u001b[38;5;241m.\u001b[39mappend(aggregate_segment_sims(segment_sims, with_std, with_support))\n",
      "File \u001b[1;32mc:\\Users\\Daito\\miniconda3\\envs\\NLP\\Lib\\site-packages\\gensim\\topic_coherence\\indirect_confirmation_measure.py:248\u001b[0m, in \u001b[0;36mContextVectorComputer.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_context_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daito\\miniconda3\\envs\\NLP\\Lib\\site-packages\\gensim\\topic_coherence\\indirect_confirmation_measure.py:269\u001b[0m, in \u001b[0;36mContextVectorComputer.compute_context_vector\u001b[1;34m(self, segment_word_ids, topic_word_ids)\u001b[0m\n\u001b[0;32m    267\u001b[0m context_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_vector_cache\u001b[38;5;241m.\u001b[39mget(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context_vector \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 269\u001b[0m     context_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_seg\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment_word_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopic_word_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_vector_cache[key] \u001b[38;5;241m=\u001b[39m context_vector\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context_vector\n",
      "File \u001b[1;32mc:\\Users\\Daito\\miniconda3\\envs\\NLP\\Lib\\site-packages\\gensim\\topic_coherence\\indirect_confirmation_measure.py:296\u001b[0m, in \u001b[0;36mContextVectorComputer._make_seg\u001b[1;34m(self, segment_word_ids, topic_word_ids)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28msorted\u001b[39m((w_i, w_j))) \u001b[38;5;28;01mfor\u001b[39;00m w_i \u001b[38;5;129;01min\u001b[39;00m segment_word_ids):\n\u001b[0;32m    295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pair \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim_cache:\n\u001b[1;32m--> 296\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim_cache[pair] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccumulator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m         context_vector[idx] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msim_cache[pair] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m context_vector\u001b[38;5;241m.\u001b[39mtocsr()\n",
      "File \u001b[1;32mc:\\Users\\Daito\\miniconda3\\envs\\NLP\\Lib\\site-packages\\gensim\\topic_coherence\\indirect_confirmation_measure.py:319\u001b[0m, in \u001b[0;36m_pair_npmi\u001b[1;34m(pair, accumulator)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pair_npmi\u001b[39m(pair, accumulator):\n\u001b[0;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute normalized pairwise mutual information (**NPMI**) between a pair of words.\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    317\u001b[0m \n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlog_ratio_measure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpair\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Daito\\miniconda3\\envs\\NLP\\Lib\\site-packages\\gensim\\topic_coherence\\direct_confirmation_measure.py:193\u001b[0m, in \u001b[0;36mlog_ratio_measure\u001b[1;34m(segmented_topics, accumulator, normalize, with_std, with_support)\u001b[0m\n\u001b[0;32m    191\u001b[0m w_prime_count \u001b[38;5;241m=\u001b[39m accumulator[w_prime]\n\u001b[0;32m    192\u001b[0m w_star_count \u001b[38;5;241m=\u001b[39m accumulator[w_star]\n\u001b[1;32m--> 193\u001b[0m co_occur_count \u001b[38;5;241m=\u001b[39m \u001b[43maccumulator\u001b[49m\u001b[43m[\u001b[49m\u001b[43mw_prime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_star\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;66;03m# For normalized log ratio measure\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     numerator \u001b[38;5;241m=\u001b[39m log_ratio_measure([[(w_prime, w_star)]], accumulator)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Daito\\miniconda3\\envs\\NLP\\Lib\\site-packages\\gensim\\topic_coherence\\text_analysis.py:132\u001b[0m, in \u001b[0;36mBaseAnalyzer.__getitem__\u001b[1;34m(self, word_or_words)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_occurrences(word_or_words)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_co_occurrences\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mword_or_words\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daito\\miniconda3\\envs\\NLP\\Lib\\site-packages\\gensim\\topic_coherence\\text_analysis.py:213\u001b[0m, in \u001b[0;36mUsesDictionary.get_co_occurrences\u001b[1;34m(self, word1, word2)\u001b[0m\n\u001b[0;32m    211\u001b[0m word_id1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_word2_contiguous_id(word1)\n\u001b[0;32m    212\u001b[0m word_id2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_word2_contiguous_id(word2)\n\u001b[1;32m--> 213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_co_occurrences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_id1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_id2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daito\\miniconda3\\envs\\NLP\\Lib\\site-packages\\gensim\\topic_coherence\\text_analysis.py:396\u001b[0m, in \u001b[0;36mWordOccurrenceAccumulator._get_co_occurrences\u001b[1;34m(self, word_id1, word_id2)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_co_occurrences\u001b[39m(\u001b[38;5;28mself\u001b[39m, word_id1, word_id2):\n\u001b[1;32m--> 396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_co_occurrences\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword_id1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_id2\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Daito\\miniconda3\\envs\\NLP\\Lib\\site-packages\\scipy\\sparse\\_index.py:49\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(row, INT_TYPES):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, INT_TYPES):\n\u001b[1;32m---> 49\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_intXint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_on_1d_array_slice()\n",
      "File \u001b[1;32mc:\\Users\\Daito\\miniconda3\\envs\\NLP\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:656\u001b[0m, in \u001b[0;36m_cs_matrix._get_intXint\u001b[1;34m(self, row, col)\u001b[0m\n\u001b[0;32m    654\u001b[0m M, N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    655\u001b[0m major, minor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap((row, col))\n\u001b[1;32m--> 656\u001b[0m indptr, indices, data \u001b[38;5;241m=\u001b[39m \u001b[43mget_csr_submatrix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[43m    \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    658\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmajor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39msum(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result={\"num_topics\":[], \"coherence_score_cv\":[],\"coherence_score_npmi\":[]}\n",
    "\n",
    "for n in range(50, 65):\n",
    "    lda_model = LdaModel(corpus, num_topics=n, id2word=dictionary)\n",
    "    coherence_model_cv= CoherenceModel(model=lda_model, texts=l_texts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score_cv = coherence_model_cv.get_coherence()\n",
    "    coherence_model_npmi= CoherenceModel(model=lda_model, texts=l_texts, dictionary=dictionary, coherence='c_npmi')\n",
    "    coherence_score_npmi = coherence_model_npmi.get_coherence()\n",
    "    print(\"Number of topics: \", n, \" Coherence Score: \", coherence_score_npmi,coherence_score_cv)\n",
    "    result[\"num_topics\"].append(n)\n",
    "    result[\"coherence_score_cv\"].append(coherence_score_cv)\n",
    "    result[\"coherence_score_npmi\"].append(coherence_score_npmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_n=result[\"num_topics\"][np.argmax(result[\"coherence_score_cv\"])]\n",
    "lda_model = LdaModel(corpus, num_topics=n, id2word=dictionary)\n",
    "coherence_model_cv= CoherenceModel(model=lda_model, texts=l_texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score_cv = coherence_model_cv.get_coherence()\n",
    "coherence_model_npmi= CoherenceModel(model=lda_model, texts=l_texts, dictionary=dictionary, coherence='c_npmi')\n",
    "coherence_score_npmi = coherence_model_npmi.get_coherence()\n",
    "print(\"Optimal number of topics: \", optimal_n, \" Coherence Score: \", coherence_score_npmi,coherence_score_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_model = LsiModel(corpus, num_topics=optimal_n, id2word=dictionary)\n",
    "coherence_model_cv= CoherenceModel(model=lsi_model, texts=l_texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score_cv = coherence_model_cv.get_coherence()\n",
    "coherence_model_npmi= CoherenceModel(model=lsi_model, texts=l_texts, dictionary=dictionary, coherence='c_npmi')\n",
    "coherence_score_npmi = coherence_model_npmi.get_coherence()\n",
    "print(\"Number of topics: \", n, \" Coherence Score: \", coherence_score_npmi,coherence_score_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "#Not possible with LSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec Bertopic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation=bertopic.representation.KeyBERTInspired()\n",
    "model_trained_representation= bertopic.BERTopic(representation_model=representation,nr_topics=55)\n",
    "topics,probs = model_trained_representation.fit_transform(dataset['headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(l_texts)\n",
    "coherence_model= CoherenceModel(model=model_trained_representation, texts=l_texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score_cv = coherence_model.get_coherence()\n",
    "coherence_model= CoherenceModel(model=model_trained_representation, texts=l_texts, dictionary=dictionary, coherence='c_npmi')\n",
    "coherence_score_c_npmi = coherence_model.get_coherence()\n",
    "print(\"Coherence Score: \", coherence_score_cv,coherence_score_c_npmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained_representation.visualize_topics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
