{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9e_Rmpt0B_Oa"
      },
      "outputs": [],
      "source": [
        "# import necessary libraries\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def force_format(texts):\n",
        "    return [str(t) for t in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tFCI60p8GyQ6"
      },
      "outputs": [],
      "source": [
        "def compute_word_occurences(texts):\n",
        "    words = itertools.chain.from_iterable(texts)\n",
        "    word_count = pd.Series(words).value_counts()\n",
        "    word_count = pd.DataFrame({\"Word\": word_count.index, \"Count\": word_count.values})\n",
        "    return word_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_l_texts(text_file):\n",
        "    l_texts=[]\n",
        "    with open(text_file, \"r\") as f:\n",
        "        line = f.readlines()\n",
        "        list_line = [l.strip() for l in line]\n",
        "        for l in list_line:\n",
        "            l_texts.append(ast.literal_eval(l))\n",
        "    return l_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = pd.read_json(\"News_Category_Dataset_v2.json\", lines=True, dtype={\"headline\": str})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "texts = force_format(dataset[\"headline\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-12-07T10:50:05.882854Z",
          "start_time": "2020-12-07T10:49:42.724726Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Vov7lwqCG4O",
        "outputId": "9fcf3553-3f37-4be6-f4eb-09c5bc6e6c0e"
      },
      "outputs": [],
      "source": [
        "l_texts = get_l_texts(\"l_texts.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eMxYmxOktWw"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NvDsjgk3P3EE"
      },
      "outputs": [],
      "source": [
        "#Import\n",
        "import bertopic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nmodel= bertopic.BERTopic()\\ntopics = model.fit_transform(l_texts)\\nmodel.visualize_topics()\\nmodel.get_topic_info()\\n'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "model= bertopic.BERTopic()\n",
        "topics = model.fit_transform(l_texts)\n",
        "model.visualize_topics()\n",
        "model.get_topic_info()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count</th>\n",
              "      <th>Name</th>\n",
              "      <th>Representation</th>\n",
              "      <th>Representative_Docs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>82981</td>\n",
              "      <td>-1_video_mom_photos_school</td>\n",
              "      <td>[video, mom, photos, school, police, fashion, ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>812</td>\n",
              "      <td>0_fitness_workout_gym_exercise</td>\n",
              "      <td>[fitness, workout, gym, exercise, exercises, w...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>729</td>\n",
              "      <td>1_food_diet_nutrition_foods</td>\n",
              "      <td>[food, diet, nutrition, foods, diets, eat, cra...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>706</td>\n",
              "      <td>2_airlines_airline_flight_passenger</td>\n",
              "      <td>[airlines, airline, flight, passenger, flights...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>697</td>\n",
              "      <td>3_climate_change_epa_warming</td>\n",
              "      <td>[climate, change, epa, warming, deniers, envir...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2385</th>\n",
              "      <td>2384</td>\n",
              "      <td>10</td>\n",
              "      <td>2384_grammys_grammy_carpet_tacky</td>\n",
              "      <td>[grammys, grammy, carpet, tacky, bestdressed, ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2386</th>\n",
              "      <td>2385</td>\n",
              "      <td>10</td>\n",
              "      <td>2385_despacito_yankee_calculators_overplayed</td>\n",
              "      <td>[despacito, yankee, calculators, overplayed, s...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2387</th>\n",
              "      <td>2386</td>\n",
              "      <td>10</td>\n",
              "      <td>2386_stem_subjects_scienceminded_girls</td>\n",
              "      <td>[stem, subjects, scienceminded, girls, ripples...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2388</th>\n",
              "      <td>2387</td>\n",
              "      <td>10</td>\n",
              "      <td>2387_alchemists_stutz_phil_piatigorsky</td>\n",
              "      <td>[alchemists, stutz, phil, piatigorsky, gregor,...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2389</th>\n",
              "      <td>2388</td>\n",
              "      <td>10</td>\n",
              "      <td>2388_nightclub_orlando_pulse_rampage</td>\n",
              "      <td>[nightclub, orlando, pulse, rampage, clubgoer,...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2390 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Topic  Count                                          Name  \\\n",
              "0        -1  82981                    -1_video_mom_photos_school   \n",
              "1         0    812                0_fitness_workout_gym_exercise   \n",
              "2         1    729                   1_food_diet_nutrition_foods   \n",
              "3         2    706           2_airlines_airline_flight_passenger   \n",
              "4         3    697                  3_climate_change_epa_warming   \n",
              "...     ...    ...                                           ...   \n",
              "2385   2384     10              2384_grammys_grammy_carpet_tacky   \n",
              "2386   2385     10  2385_despacito_yankee_calculators_overplayed   \n",
              "2387   2386     10        2386_stem_subjects_scienceminded_girls   \n",
              "2388   2387     10        2387_alchemists_stutz_phil_piatigorsky   \n",
              "2389   2388     10          2388_nightclub_orlando_pulse_rampage   \n",
              "\n",
              "                                         Representation  Representative_Docs  \n",
              "0     [video, mom, photos, school, police, fashion, ...                  NaN  \n",
              "1     [fitness, workout, gym, exercise, exercises, w...                  NaN  \n",
              "2     [food, diet, nutrition, foods, diets, eat, cra...                  NaN  \n",
              "3     [airlines, airline, flight, passenger, flights...                  NaN  \n",
              "4     [climate, change, epa, warming, deniers, envir...                  NaN  \n",
              "...                                                 ...                  ...  \n",
              "2385  [grammys, grammy, carpet, tacky, bestdressed, ...                  NaN  \n",
              "2386  [despacito, yankee, calculators, overplayed, s...                  NaN  \n",
              "2387  [stem, subjects, scienceminded, girls, ripples...                  NaN  \n",
              "2388  [alchemists, stutz, phil, piatigorsky, gregor,...                  NaN  \n",
              "2389  [nightclub, orlando, pulse, rampage, clubgoer,...                  NaN  \n",
              "\n",
              "[2390 rows x 5 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=bertopic.BERTopic()\n",
        "model=model.load(\"trained_model_pytorch\")\n",
        "\n",
        "model.get_topic_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'keys'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[42], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m dict_model\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_topics()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_clusters\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mdict_model\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m())\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
          ]
        }
      ],
      "source": [
        "n_clusters=model.get_topic_info().shape[0]\n",
        "dict_model=model.get_topics()\n",
        "\n",
        "for i in range(n_clusters-1):\n",
        "    print(\"Cluster \",i)\n",
        "    list_words=[for dict_model[i]]\n",
        "    print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
